{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\RBG-codes-20230901T140438Z-001\\Cycada\\cycada\n"
     ]
    }
   ],
   "source": [
    "%cd d:\\RBG-codes-20230901T140438Z-001\\Cycada\\cycada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is num_epoch  200\n",
      "this is num epoch 200\n",
      "-------Training net--------\n",
      "LeNet(\n",
      "  (conv_params): Sequential(\n",
      "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Dropout2d(p=0.5, inplace=False)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (fc_params): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "get dataset: icdar2013to2015 FY/icdar2013to2015 train\n",
      "get dataset: icdar2013to2015 FY/icdar2013to2015 test\n",
      "Training LeNet model for icdar2013to2015\n",
      "200\n",
      "0\n",
      "[Train] Epoch: 0 [0/846 (0%)]\tLoss: 0.615906  Acc: 78.91\n",
      "1\n",
      "[Train] Epoch: 1 [0/846 (0%)]\tLoss: 0.317487  Acc: 100.00\n",
      "2\n",
      "[Train] Epoch: 2 [0/846 (0%)]\tLoss: 0.126692  Acc: 100.00\n",
      "3\n",
      "[Train] Epoch: 3 [0/846 (0%)]\tLoss: 0.033991  Acc: 100.00\n",
      "4\n",
      "[Train] Epoch: 4 [0/846 (0%)]\tLoss: 0.016902  Acc: 100.00\n",
      "5\n",
      "[Train] Epoch: 5 [0/846 (0%)]\tLoss: 0.004120  Acc: 100.00\n",
      "6\n",
      "[Train] Epoch: 6 [0/846 (0%)]\tLoss: 0.002495  Acc: 100.00\n",
      "7\n",
      "[Train] Epoch: 7 [0/846 (0%)]\tLoss: 0.001390  Acc: 100.00\n",
      "8\n",
      "[Train] Epoch: 8 [0/846 (0%)]\tLoss: 0.001216  Acc: 100.00\n",
      "9\n",
      "[Train] Epoch: 9 [0/846 (0%)]\tLoss: 0.001380  Acc: 100.00\n",
      "10\n",
      "[Train] Epoch: 10 [0/846 (0%)]\tLoss: 0.001074  Acc: 100.00\n",
      "11\n",
      "[Train] Epoch: 11 [0/846 (0%)]\tLoss: 0.000789  Acc: 100.00\n",
      "12\n",
      "[Train] Epoch: 12 [0/846 (0%)]\tLoss: 0.000611  Acc: 100.00\n",
      "13\n",
      "[Train] Epoch: 13 [0/846 (0%)]\tLoss: 0.000611  Acc: 100.00\n",
      "14\n",
      "[Train] Epoch: 14 [0/846 (0%)]\tLoss: 0.000608  Acc: 100.00\n",
      "15\n",
      "[Train] Epoch: 15 [0/846 (0%)]\tLoss: 0.000453  Acc: 100.00\n",
      "16\n",
      "[Train] Epoch: 16 [0/846 (0%)]\tLoss: 0.000606  Acc: 100.00\n",
      "17\n",
      "[Train] Epoch: 17 [0/846 (0%)]\tLoss: 0.000439  Acc: 100.00\n",
      "18\n",
      "[Train] Epoch: 18 [0/846 (0%)]\tLoss: 0.003200  Acc: 100.00\n",
      "19\n",
      "[Train] Epoch: 19 [0/846 (0%)]\tLoss: 0.000461  Acc: 100.00\n",
      "20\n",
      "[Train] Epoch: 20 [0/846 (0%)]\tLoss: 0.000343  Acc: 100.00\n",
      "21\n",
      "[Train] Epoch: 21 [0/846 (0%)]\tLoss: 0.000263  Acc: 100.00\n",
      "22\n",
      "[Train] Epoch: 22 [0/846 (0%)]\tLoss: 0.000283  Acc: 100.00\n",
      "23\n",
      "[Train] Epoch: 23 [0/846 (0%)]\tLoss: 0.000247  Acc: 100.00\n",
      "24\n",
      "[Train] Epoch: 24 [0/846 (0%)]\tLoss: 0.000143  Acc: 100.00\n",
      "25\n",
      "[Train] Epoch: 25 [0/846 (0%)]\tLoss: 0.000774  Acc: 100.00\n",
      "26\n",
      "[Train] Epoch: 26 [0/846 (0%)]\tLoss: 0.000159  Acc: 100.00\n",
      "27\n",
      "[Train] Epoch: 27 [0/846 (0%)]\tLoss: 0.000197  Acc: 100.00\n",
      "28\n",
      "[Train] Epoch: 28 [0/846 (0%)]\tLoss: 0.000153  Acc: 100.00\n",
      "29\n",
      "[Train] Epoch: 29 [0/846 (0%)]\tLoss: 0.000137  Acc: 100.00\n",
      "30\n",
      "[Train] Epoch: 30 [0/846 (0%)]\tLoss: 0.000173  Acc: 100.00\n",
      "31\n",
      "[Train] Epoch: 31 [0/846 (0%)]\tLoss: 0.002483  Acc: 100.00\n",
      "32\n",
      "[Train] Epoch: 32 [0/846 (0%)]\tLoss: 0.000261  Acc: 100.00\n",
      "33\n",
      "[Train] Epoch: 33 [0/846 (0%)]\tLoss: 0.000099  Acc: 100.00\n",
      "34\n",
      "[Train] Epoch: 34 [0/846 (0%)]\tLoss: 0.000032  Acc: 100.00\n",
      "35\n",
      "[Train] Epoch: 35 [0/846 (0%)]\tLoss: 0.000042  Acc: 100.00\n",
      "36\n",
      "[Train] Epoch: 36 [0/846 (0%)]\tLoss: 0.002409  Acc: 100.00\n",
      "37\n",
      "[Train] Epoch: 37 [0/846 (0%)]\tLoss: 0.000072  Acc: 100.00\n",
      "38\n",
      "[Train] Epoch: 38 [0/846 (0%)]\tLoss: 0.002013  Acc: 100.00\n",
      "39\n",
      "[Train] Epoch: 39 [0/846 (0%)]\tLoss: 0.002187  Acc: 100.00\n",
      "40\n",
      "[Train] Epoch: 40 [0/846 (0%)]\tLoss: 0.000042  Acc: 100.00\n",
      "41\n",
      "[Train] Epoch: 41 [0/846 (0%)]\tLoss: 0.000063  Acc: 100.00\n",
      "42\n",
      "[Train] Epoch: 42 [0/846 (0%)]\tLoss: 0.000068  Acc: 100.00\n",
      "43\n",
      "[Train] Epoch: 43 [0/846 (0%)]\tLoss: 0.000079  Acc: 100.00\n",
      "44\n",
      "[Train] Epoch: 44 [0/846 (0%)]\tLoss: 0.000021  Acc: 100.00\n",
      "45\n",
      "[Train] Epoch: 45 [0/846 (0%)]\tLoss: 0.000058  Acc: 100.00\n",
      "46\n",
      "[Train] Epoch: 46 [0/846 (0%)]\tLoss: 0.000053  Acc: 100.00\n",
      "47\n",
      "[Train] Epoch: 47 [0/846 (0%)]\tLoss: 0.000049  Acc: 100.00\n",
      "48\n",
      "[Train] Epoch: 48 [0/846 (0%)]\tLoss: 0.001535  Acc: 100.00\n",
      "49\n",
      "[Train] Epoch: 49 [0/846 (0%)]\tLoss: 0.000082  Acc: 100.00\n",
      "50\n",
      "[Train] Epoch: 50 [0/846 (0%)]\tLoss: 0.000035  Acc: 100.00\n",
      "51\n",
      "[Train] Epoch: 51 [0/846 (0%)]\tLoss: 0.001664  Acc: 100.00\n",
      "52\n",
      "[Train] Epoch: 52 [0/846 (0%)]\tLoss: 0.000015  Acc: 100.00\n",
      "53\n",
      "[Train] Epoch: 53 [0/846 (0%)]\tLoss: 0.001196  Acc: 100.00\n",
      "54\n",
      "[Train] Epoch: 54 [0/846 (0%)]\tLoss: 0.000036  Acc: 100.00\n",
      "55\n",
      "[Train] Epoch: 55 [0/846 (0%)]\tLoss: 0.000013  Acc: 100.00\n",
      "56\n",
      "[Train] Epoch: 56 [0/846 (0%)]\tLoss: 0.000014  Acc: 100.00\n",
      "57\n",
      "[Train] Epoch: 57 [0/846 (0%)]\tLoss: 0.000016  Acc: 100.00\n",
      "58\n",
      "[Train] Epoch: 58 [0/846 (0%)]\tLoss: 0.000020  Acc: 100.00\n",
      "59\n",
      "[Train] Epoch: 59 [0/846 (0%)]\tLoss: 0.000047  Acc: 100.00\n",
      "60\n",
      "[Train] Epoch: 60 [0/846 (0%)]\tLoss: 0.000007  Acc: 100.00\n",
      "61\n",
      "[Train] Epoch: 61 [0/846 (0%)]\tLoss: 0.000029  Acc: 100.00\n",
      "62\n",
      "[Train] Epoch: 62 [0/846 (0%)]\tLoss: 0.000018  Acc: 100.00\n",
      "63\n",
      "[Train] Epoch: 63 [0/846 (0%)]\tLoss: 0.000036  Acc: 100.00\n",
      "64\n",
      "[Train] Epoch: 64 [0/846 (0%)]\tLoss: 0.000044  Acc: 100.00\n",
      "65\n",
      "[Train] Epoch: 65 [0/846 (0%)]\tLoss: 0.000046  Acc: 100.00\n",
      "66\n",
      "[Train] Epoch: 66 [0/846 (0%)]\tLoss: 0.000013  Acc: 100.00\n",
      "67\n",
      "[Train] Epoch: 67 [0/846 (0%)]\tLoss: 0.000007  Acc: 100.00\n",
      "68\n",
      "[Train] Epoch: 68 [0/846 (0%)]\tLoss: 0.000006  Acc: 100.00\n",
      "69\n",
      "[Train] Epoch: 69 [0/846 (0%)]\tLoss: 0.000028  Acc: 100.00\n",
      "70\n",
      "[Train] Epoch: 70 [0/846 (0%)]\tLoss: 0.000015  Acc: 100.00\n",
      "71\n",
      "[Train] Epoch: 71 [0/846 (0%)]\tLoss: 0.000014  Acc: 100.00\n",
      "72\n",
      "[Train] Epoch: 72 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "73\n",
      "[Train] Epoch: 73 [0/846 (0%)]\tLoss: 0.001346  Acc: 100.00\n",
      "74\n",
      "[Train] Epoch: 74 [0/846 (0%)]\tLoss: 0.000019  Acc: 100.00\n",
      "75\n",
      "[Train] Epoch: 75 [0/846 (0%)]\tLoss: 0.000016  Acc: 100.00\n",
      "76\n",
      "[Train] Epoch: 76 [0/846 (0%)]\tLoss: 0.000020  Acc: 100.00\n",
      "77\n",
      "[Train] Epoch: 77 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "78\n",
      "[Train] Epoch: 78 [0/846 (0%)]\tLoss: 0.000045  Acc: 100.00\n",
      "79\n",
      "[Train] Epoch: 79 [0/846 (0%)]\tLoss: 0.000725  Acc: 100.00\n",
      "80\n",
      "[Train] Epoch: 80 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "81\n",
      "[Train] Epoch: 81 [0/846 (0%)]\tLoss: 0.001113  Acc: 100.00\n",
      "82\n",
      "[Train] Epoch: 82 [0/846 (0%)]\tLoss: 0.000949  Acc: 100.00\n",
      "83\n",
      "[Train] Epoch: 83 [0/846 (0%)]\tLoss: 0.000006  Acc: 100.00\n",
      "84\n",
      "[Train] Epoch: 84 [0/846 (0%)]\tLoss: 0.000013  Acc: 100.00\n",
      "85\n",
      "[Train] Epoch: 85 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "86\n",
      "[Train] Epoch: 86 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "87\n",
      "[Train] Epoch: 87 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "88\n",
      "[Train] Epoch: 88 [0/846 (0%)]\tLoss: 0.000009  Acc: 100.00\n",
      "89\n",
      "[Train] Epoch: 89 [0/846 (0%)]\tLoss: 0.001023  Acc: 100.00\n",
      "90\n",
      "[Train] Epoch: 90 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "91\n",
      "[Train] Epoch: 91 [0/846 (0%)]\tLoss: 0.000005  Acc: 100.00\n",
      "92\n",
      "[Train] Epoch: 92 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "93\n",
      "[Train] Epoch: 93 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "94\n",
      "[Train] Epoch: 94 [0/846 (0%)]\tLoss: 0.000005  Acc: 100.00\n",
      "95\n",
      "[Train] Epoch: 95 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "96\n",
      "[Train] Epoch: 96 [0/846 (0%)]\tLoss: 0.000641  Acc: 100.00\n",
      "97\n",
      "[Train] Epoch: 97 [0/846 (0%)]\tLoss: 0.000013  Acc: 100.00\n",
      "98\n",
      "[Train] Epoch: 98 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "99\n",
      "[Train] Epoch: 99 [0/846 (0%)]\tLoss: 0.000005  Acc: 100.00\n",
      "100\n",
      "[Train] Epoch: 100 [0/846 (0%)]\tLoss: 0.000034  Acc: 100.00\n",
      "101\n",
      "[Train] Epoch: 101 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "102\n",
      "[Train] Epoch: 102 [0/846 (0%)]\tLoss: 0.000012  Acc: 100.00\n",
      "103\n",
      "[Train] Epoch: 103 [0/846 (0%)]\tLoss: 0.001269  Acc: 100.00\n",
      "104\n",
      "[Train] Epoch: 104 [0/846 (0%)]\tLoss: 0.000361  Acc: 100.00\n",
      "105\n",
      "[Train] Epoch: 105 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "106\n",
      "[Train] Epoch: 106 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "107\n",
      "[Train] Epoch: 107 [0/846 (0%)]\tLoss: 0.000005  Acc: 100.00\n",
      "108\n",
      "[Train] Epoch: 108 [0/846 (0%)]\tLoss: 0.000006  Acc: 100.00\n",
      "109\n",
      "[Train] Epoch: 109 [0/846 (0%)]\tLoss: 0.000031  Acc: 100.00\n",
      "110\n",
      "[Train] Epoch: 110 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "111\n",
      "[Train] Epoch: 111 [0/846 (0%)]\tLoss: 0.000013  Acc: 100.00\n",
      "112\n",
      "[Train] Epoch: 112 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "113\n",
      "[Train] Epoch: 113 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "114\n",
      "[Train] Epoch: 114 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "115\n",
      "[Train] Epoch: 115 [0/846 (0%)]\tLoss: 0.000012  Acc: 100.00\n",
      "116\n",
      "[Train] Epoch: 116 [0/846 (0%)]\tLoss: 0.000006  Acc: 100.00\n",
      "117\n",
      "[Train] Epoch: 117 [0/846 (0%)]\tLoss: 0.000006  Acc: 100.00\n",
      "118\n",
      "[Train] Epoch: 118 [0/846 (0%)]\tLoss: 0.000233  Acc: 100.00\n",
      "119\n",
      "[Train] Epoch: 119 [0/846 (0%)]\tLoss: 0.000005  Acc: 100.00\n",
      "120\n",
      "[Train] Epoch: 120 [0/846 (0%)]\tLoss: 0.000006  Acc: 100.00\n",
      "121\n",
      "[Train] Epoch: 121 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "122\n",
      "[Train] Epoch: 122 [0/846 (0%)]\tLoss: 0.000018  Acc: 100.00\n",
      "123\n",
      "[Train] Epoch: 123 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "124\n",
      "[Train] Epoch: 124 [0/846 (0%)]\tLoss: 0.000005  Acc: 100.00\n",
      "125\n",
      "[Train] Epoch: 125 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "126\n",
      "[Train] Epoch: 126 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "127\n",
      "[Train] Epoch: 127 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "128\n",
      "[Train] Epoch: 128 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "129\n",
      "[Train] Epoch: 129 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "130\n",
      "[Train] Epoch: 130 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "131\n",
      "[Train] Epoch: 131 [0/846 (0%)]\tLoss: 0.000598  Acc: 100.00\n",
      "132\n",
      "[Train] Epoch: 132 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "133\n",
      "[Train] Epoch: 133 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "134\n",
      "[Train] Epoch: 134 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "135\n",
      "[Train] Epoch: 135 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "136\n",
      "[Train] Epoch: 136 [0/846 (0%)]\tLoss: 0.000245  Acc: 100.00\n",
      "137\n",
      "[Train] Epoch: 137 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "138\n",
      "[Train] Epoch: 138 [0/846 (0%)]\tLoss: 0.000006  Acc: 100.00\n",
      "139\n",
      "[Train] Epoch: 139 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "140\n",
      "[Train] Epoch: 140 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "141\n",
      "[Train] Epoch: 141 [0/846 (0%)]\tLoss: 0.001359  Acc: 100.00\n",
      "142\n",
      "[Train] Epoch: 142 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "143\n",
      "[Train] Epoch: 143 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "144\n",
      "[Train] Epoch: 144 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "145\n",
      "[Train] Epoch: 145 [0/846 (0%)]\tLoss: 0.000012  Acc: 100.00\n",
      "146\n",
      "[Train] Epoch: 146 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "147\n",
      "[Train] Epoch: 147 [0/846 (0%)]\tLoss: 0.000016  Acc: 100.00\n",
      "148\n",
      "[Train] Epoch: 148 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "149\n",
      "[Train] Epoch: 149 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "150\n",
      "[Train] Epoch: 150 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "151\n",
      "[Train] Epoch: 151 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "152\n",
      "[Train] Epoch: 152 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "153\n",
      "[Train] Epoch: 153 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "154\n",
      "[Train] Epoch: 154 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "155\n",
      "[Train] Epoch: 155 [0/846 (0%)]\tLoss: 0.000008  Acc: 100.00\n",
      "156\n",
      "[Train] Epoch: 156 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "157\n",
      "[Train] Epoch: 157 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "158\n",
      "[Train] Epoch: 158 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "159\n",
      "[Train] Epoch: 159 [0/846 (0%)]\tLoss: 0.000227  Acc: 100.00\n",
      "160\n",
      "[Train] Epoch: 160 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "161\n",
      "[Train] Epoch: 161 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "162\n",
      "[Train] Epoch: 162 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "163\n",
      "[Train] Epoch: 163 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "164\n",
      "[Train] Epoch: 164 [0/846 (0%)]\tLoss: 0.000007  Acc: 100.00\n",
      "165\n",
      "[Train] Epoch: 165 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "166\n",
      "[Train] Epoch: 166 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "167\n",
      "[Train] Epoch: 167 [0/846 (0%)]\tLoss: 0.001037  Acc: 100.00\n",
      "168\n",
      "[Train] Epoch: 168 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "169\n",
      "[Train] Epoch: 169 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "170\n",
      "[Train] Epoch: 170 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "171\n",
      "[Train] Epoch: 171 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "172\n",
      "[Train] Epoch: 172 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "173\n",
      "[Train] Epoch: 173 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "174\n",
      "[Train] Epoch: 174 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "175\n",
      "[Train] Epoch: 175 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "176\n",
      "[Train] Epoch: 176 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "177\n",
      "[Train] Epoch: 177 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "178\n",
      "[Train] Epoch: 178 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "179\n",
      "[Train] Epoch: 179 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "180\n",
      "[Train] Epoch: 180 [0/846 (0%)]\tLoss: 0.000007  Acc: 100.00\n",
      "181\n",
      "[Train] Epoch: 181 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "182\n",
      "[Train] Epoch: 182 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "183\n",
      "[Train] Epoch: 183 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "184\n",
      "[Train] Epoch: 184 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "185\n",
      "[Train] Epoch: 185 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "186\n",
      "[Train] Epoch: 186 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "187\n",
      "[Train] Epoch: 187 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "188\n",
      "[Train] Epoch: 188 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "189\n",
      "[Train] Epoch: 189 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "190\n",
      "[Train] Epoch: 190 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "191\n",
      "[Train] Epoch: 191 [0/846 (0%)]\tLoss: 0.000003  Acc: 100.00\n",
      "192\n",
      "[Train] Epoch: 192 [0/846 (0%)]\tLoss: 0.000002  Acc: 100.00\n",
      "193\n",
      "[Train] Epoch: 193 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "194\n",
      "[Train] Epoch: 194 [0/846 (0%)]\tLoss: 0.000439  Acc: 100.00\n",
      "195\n",
      "[Train] Epoch: 195 [0/846 (0%)]\tLoss: 0.000001  Acc: 100.00\n",
      "196\n",
      "[Train] Epoch: 196 [0/846 (0%)]\tLoss: 0.000000  Acc: 100.00\n",
      "197\n",
      "[Train] Epoch: 197 [0/846 (0%)]\tLoss: 0.000625  Acc: 100.00\n",
      "198\n",
      "[Train] Epoch: 198 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "199\n",
      "[Train] Epoch: 199 [0/846 (0%)]\tLoss: 0.000004  Acc: 100.00\n",
      "Evaluating LeNet-icdar2013to2015 model on icdar2013to2015 test set\n",
      "[Evaluate] Average loss: 0.0000, Accuracy: 1093/1093 (100.00%)\n",
      "\n",
      "Saving to results/icdar2013to2015_to_icdar2013to2015/iter_1\\LeNet_net_icdar2013to2015.pth\n",
      "\n",
      "this is num_epoch  500\n",
      "this is debug\n",
      "this is num_epoch  500\n",
      "AddaNet(\n",
      "  (cls_criterion): CrossEntropyLoss()\n",
      "  (gan_criterion): CrossEntropyLoss()\n",
      "  (src_net): LeNet(\n",
      "    (conv_params): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (4): Dropout2d(p=0.5, inplace=False)\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): ReLU()\n",
      "    )\n",
      "    (fc_params): Linear(in_features=800, out_features=500, bias=True)\n",
      "    (classifier): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=500, out_features=2, bias=True)\n",
      "    )\n",
      "    (criterion): CrossEntropyLoss()\n",
      "  )\n",
      "  (tgt_net): LeNet(\n",
      "    (conv_params): Sequential(\n",
      "      (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (4): Dropout2d(p=0.5, inplace=False)\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): ReLU()\n",
      "    )\n",
      "    (fc_params): Linear(in_features=800, out_features=500, bias=True)\n",
      "    (classifier): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=500, out_features=2, bias=True)\n",
      "    )\n",
      "    (criterion): CrossEntropyLoss()\n",
      "  )\n",
      "  (discriminator): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Training Adda LeNet model for icdar2013to2015->icdar2013to2015\n",
      "get dataset: icdar2013to2015 FY/icdar2013to2015 train\n",
      "get dataset: icdar2013to2015 FY/icdar2013to2015 train\n",
      "0 500\n",
      "this is epoch for ADDA: 0\n",
      "this is epoch for batch_idx: 0\n",
      "[Train Adda] Epoch: 0 [0/846 (0.00%)] acc: 50.0 D: 1.101\n",
      "this is epoch for batch_idx: 1\n",
      "this is epoch for batch_idx: 2\n",
      "this is epoch for batch_idx: 3\n",
      "this is epoch for batch_idx: 4\n",
      "this is epoch for batch_idx: 5\n",
      "this is epoch for batch_idx: 6\n",
      "No suitable discriminator\n",
      "Saving to results/icdar2013to2015_to_icdar2013to2015/iter_1\\adda_LeNet_net_icdar2013to2015_icdar2013to2015.pth\n",
      "\n",
      "----------------\n",
      "Test set: icdar2013to2015\n",
      "----------------\n",
      "Evaluating icdar2013to2015 source model: results/icdar2013to2015_to_icdar2013to2015/iter_1\\LeNet_net_icdar2013to2015.pth\n",
      "get dataset: icdar2013to2015 FY/icdar2013to2015 test\n",
      "[Evaluate] Average loss: 0.0000, Accuracy: 1093/1093 (100.00%)\n",
      "\n",
      "0\n",
      "Evaluating icdar2013to2015->icdar2013to2015 adda model: results/icdar2013to2015_to_icdar2013to2015/iter_1\\adda_LeNet_net_icdar2013to2015_icdar2013to2015.pth\n",
      "get dataset: icdar2013to2015 FY/icdar2013to2015 test\n",
      "[Evaluate] Average loss: 0.0000, Accuracy: 1093/1093 (100.00%)\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "!python train_adda-final.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
