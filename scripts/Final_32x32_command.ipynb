{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cycada.data.data_loader import get_dataset\n",
    "import PIL.Image as Image\n",
    "from os.path import join\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd  scripts\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "def load_vocabulary(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        vocabulary = [line.strip() for line in file]\n",
    "\n",
    "    word_to_index = {word: index for index, word in enumerate(vocabulary)}\n",
    "    word_to_index[\"###\"] = len(word_to_index)  # Handle special cases\n",
    "\n",
    "    return word_to_index\n",
    "\n",
    "def word_to_label(word, word_to_index):\n",
    "    return word_to_index.get(word, 1)  # Returns the index for \"###\" if the word is not found\n",
    "\n",
    "def generate_non_text_boxes(text_boxes, img_width, img_height, num_boxes):\n",
    "    non_text_boxes = []\n",
    "    while len(non_text_boxes) < num_boxes:\n",
    "        valid_box = False\n",
    "        while not valid_box:\n",
    "            # Ensure random width and height are less than image dimensions\n",
    "            max_width = min(300, img_width - 1)\n",
    "            max_height = min(300, img_height - 1)\n",
    "\n",
    "            width = random.randint(20, max_width)\n",
    "            height = random.randint(20, max_height)\n",
    "\n",
    "            left = random.randint(0, img_width - width)\n",
    "            top = random.randint(0, img_height - height)\n",
    "            right = left + width\n",
    "            bottom = top + height\n",
    "            box = (left, top, right, bottom)\n",
    "\n",
    "            if not any(is_overlap(box, text_box) for text_box in text_boxes):\n",
    "                valid_box = True\n",
    "\n",
    "        non_text_boxes.append(box)\n",
    "\n",
    "    return non_text_boxes\n",
    "\n",
    "\n",
    "def is_overlap(box1, box2):\n",
    "    left1, top1, right1, bottom1 = box1\n",
    "    left2, top2, right2, bottom2 = box2\n",
    "    return not (right1 < left2 or right2 < left1 or bottom1 < top2 or bottom2 < top1)\n",
    "\n",
    "# Load vocabulary and process datasets as before\n",
    "\n",
    "def process_dataset(gt_folder, img_folder, output_folder, word_to_index, numeric_naming=False, diagonal_points=False, generate_non_text=False):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    images_output_folder = os.path.join(output_folder, 'images')\n",
    "    if not os.path.exists(images_output_folder):\n",
    "        os.makedirs(images_output_folder)\n",
    "\n",
    "    labels_file = os.path.join(output_folder, 'labels.txt')\n",
    "    \n",
    "    with open(labels_file, 'w') as labels_f:\n",
    "        print(labels_f)\n",
    "        img_index = 0\n",
    "\n",
    "        for gt_file in os.listdir(gt_folder):\n",
    "\n",
    "            text_boxes = []  # List to store text box coordinates\n",
    "\n",
    "            gt_path = os.path.join(gt_folder, gt_file)\n",
    "            print(gt_path)\n",
    "\n",
    "            if numeric_naming:\n",
    "                # Extract the numeric part for numeric naming convention\n",
    "                numeric_part = gt_file.split('_')[1].split('.')[0]  # Extracts the number from '100.txt'\n",
    "                img_name = f'{numeric_part}.jpg'  # Constructs the corresponding image filename\n",
    "            else:\n",
    "                # Extract the numeric part for 'img_X.jpg' naming convention\n",
    "                numeric_part = gt_file.split('_')[2].split('.')[0]\n",
    "                img_name = f'img_{numeric_part}.jpg'\n",
    "\n",
    "            img_path = os.path.join(img_folder, img_name)\n",
    "            print(img_path)\n",
    "\n",
    "            if os.path.exists(img_path):\n",
    "                img = Image.open(img_path)\n",
    "                try:\n",
    "                    with open(gt_path, 'r', encoding='utf-8') as f:\n",
    "                        lines = f.readlines()\n",
    "                except UnicodeDecodeError:\n",
    "                    with open(gt_path, 'r', encoding='ISO-8859-1') as f:\n",
    "                        lines = f.readlines()\n",
    "\n",
    "                for line in lines:\n",
    "\n",
    "                    if ',' in line:\n",
    "                        parts = line.strip().split(',')\n",
    "                        print (parts)\n",
    "                    else:\n",
    "                        parts = line.strip().split(' ')\n",
    "                        print (parts)\n",
    "                   \n",
    "                    if ((len(parts) == 9) or (len(parts) == 5)):\n",
    "                       \n",
    "                        if (len(parts) == 5):\n",
    "                            try:\n",
    "                                coordinates = list(map(int, parts[:4]))\n",
    "                                label_word = parts[4].upper()\n",
    "                                print(label_word)\n",
    "                                label_index = word_to_label(label_word, word_to_index)  # Convert word to label index \n",
    "                                print(label_index)\n",
    "\n",
    "                                if (label_index == 87623):\n",
    "                                    label_index=0\n",
    "                                else:\n",
    "                                    label_index=1\n",
    "                            except ValueError:\n",
    "                                continue\n",
    "                \n",
    "                            # If coordinates are diagonal points (x1, y1, x3, y3)\n",
    "                            x1, y1, x3, y3 = coordinates[0], coordinates[1], coordinates[2], coordinates[3]\n",
    "                            left, top = min(x1, x3), min(y1, y3)\n",
    "                            right, bottom = max(x1, x3), max(y1, y3)\n",
    "                            text_boxes.append((left, top, right, bottom))\n",
    "                        else:\n",
    "                            try:\n",
    "                                coordinates = list(map(int, parts[:8]))\n",
    "                                label_word = parts[8]\n",
    "                                print (label_word)\n",
    "                                \n",
    "                                label_index = word_to_label(label_word, word_to_index)  # Convert word to label index \n",
    "                                \n",
    "                                label_index=1\n",
    "\n",
    "\n",
    "                            except ValueError:\n",
    "                                continue\n",
    "                            # Regular bounding box coordinates\n",
    "                            left, top, right, bottom = min(coordinates[0::2]), min(coordinates[1::2]), max(coordinates[0::2]), max(coordinates[1::2])\n",
    "                            text_boxes.append((left, top, right, bottom))\n",
    "                                              # Generate non-text boxes\n",
    "                        img_width, img_height = img.size\n",
    "                        non_text_boxes = generate_non_text_boxes(text_boxes, img_width, img_height, len(text_boxes))\n",
    "\n",
    "                        # Define bounding box and crop image\n",
    "                        cropped_img = img.crop((left, top, right, bottom))\n",
    "                        cropped_img_path = os.path.join(images_output_folder, f'{img_index}.png')\n",
    "                        cropped_img.save(cropped_img_path)\n",
    "                        print(cropped_img_path)\n",
    "\n",
    "                        # Write label index\n",
    "                        labels_f.write(f'{img_index} {label_index}\\n')\n",
    "                        img_index += 1\n",
    "                        \n",
    "                if generate_non_text:\n",
    "                    # Generate random non-text boxes\n",
    "                    img_width, img_height = img.size\n",
    "                    non_text_boxes = generate_non_text_boxes(text_boxes, img_width, img_height, len(text_boxes))\n",
    "\n",
    "                    for box in non_text_boxes:\n",
    "                        left, top, right, bottom = box\n",
    "                        cropped_img = img.crop((left, top, right, bottom))\n",
    "                        cropped_img_path = os.path.join(images_output_folder, f'{img_index}.png')\n",
    "                        cropped_img.save(cropped_img_path)\n",
    "                        labels_f.write(f'{img_index} 0\\n')  # Label for non-text boxes is 0\n",
    "                        img_index += 1  \n",
    " # Load vocabulary\n",
    "vocabulary_file = '../GenericVocabulary.txt'  # Replace with the path to your vocabulary file\n",
    "word_to_index = load_vocabulary(vocabulary_file)\n",
    "\n",
    "# Process each dataset\n",
    "#process_dataset('../2013/Challenge2_Training_Task1_GT', '../2013/Challenge2_Training_Task12_Images', '../FY/balance/train/trainA', word_to_index, numeric_naming=True, diagonal_points=True, generate_non_text= True)\n",
    "#process_dataset('../2013/Challenge2_Test_Task1_GT', '../2013/Challenge2_Test_Task12_Images', '../FY/balance/test/testA',word_to_index, numeric_naming=False, diagonal_points=True, generate_non_text= True)\n",
    "process_dataset('../2015/ch4_training_localization_transcription_gt', '../2015/ch4_training_images', '../FY/balance2/train/trainB',word_to_index, numeric_naming=False, diagonal_points=False, generate_non_text= True)\n",
    "process_dataset('../2015/Challenge4_Test_Task1_GT', '../2015/ch4_test_images', '../FY/balance2/test/testB',word_to_index, numeric_naming=False,diagonal_points=False, generate_non_text= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def process_dataset(data_folder, output_folder, target_size=(64, 64), convert_to_rgb=False):\n",
    "    images_folder = os.path.join(data_folder, 'images')\n",
    "    labels_file = os.path.join(data_folder, 'labels.txt')\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_folder, 'images'), exist_ok=True)\n",
    "\n",
    "    with open(labels_file, 'r') as labels_f, open(os.path.join(output_folder, 'labels.txt'), 'w') as out_labels_f:\n",
    "        for line in labels_f:\n",
    "            idx, label = line.strip().split()\n",
    "            img_path = os.path.join(images_folder, f'{idx}.png')\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # Resize every image to the target size\n",
    "            img = img.resize(target_size)\n",
    "\n",
    "            if convert_to_rgb:\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            img.save(os.path.join(output_folder, 'images', f'{idx}.png'))\n",
    "            out_labels_f.write(f'{idx} {label}\\n')\n",
    "\n",
    "# Example usage remove train b test b and re run it\n",
    "base_dir = '../FY/train'\n",
    "#process_dataset(os.path.join(base_dir, 'trainA'), '../FY/cyclegan_data/ICDAR2013_2015/trainA', target_size=(128, 128), convert_to_rgb=True)\n",
    "process_dataset(os.path.join(base_dir, 'trainB'), '../FY/cyclegan_data/ICDAR2013_2015/trainB', target_size=(128, 128), convert_to_rgb=True)\n",
    "\n",
    "# Example usage\n",
    "base_dir = '../FY/test'\n",
    "#process_dataset(os.path.join(base_dir, 'testA'), '../FY/cyclegan_data/ICDAR2013_2015/testA', target_size=(128, 128), convert_to_rgb=True)\n",
    "process_dataset(os.path.join(base_dir, 'testB'), '../FY/cyclegan_data/ICDAR2013_2015/testB', target_size=(128, 128), convert_to_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# source_folder = '../FY/cyclegan_data/ICDAR2013_2015/trainA'\n",
    "# destination_folder = '../FY/icdar2013/train'\n",
    "\n",
    "# # Copy the folder\n",
    "# shutil.copytree(source_folder, destination_folder)\n",
    "\n",
    "# print(f\"Folder copied from {source_folder} to {destination_folder}\")\n",
    "\n",
    "source_folder = '../FY/cyclegan_data/ICDAR2013_2015/trainB'\n",
    "destination_folder = '../FY/icdar2015/train'\n",
    "\n",
    "# Copy the folder\n",
    "shutil.copytree(source_folder, destination_folder)\n",
    "\n",
    "print(f\"Folder copied from {source_folder} to {destination_folder}\")\n",
    "\n",
    "# source_folder = '../FY/cyclegan_data/ICDAR2013_2015/testA'\n",
    "# destination_folder = '../FY/icdar2013/test'\n",
    "\n",
    "# # Copy the folder\n",
    "# shutil.copytree(source_folder, destination_folder)\n",
    "\n",
    "# print(f\"Folder copied from {source_folder} to {destination_folder}\")\n",
    "\n",
    "source_folder = '../FY/cyclegan_data/ICDAR2013_2015/testB'\n",
    "destination_folder = '../FY/icdar2015/test'\n",
    "\n",
    "# Copy the folder\n",
    "shutil.copytree(source_folder, destination_folder)\n",
    "\n",
    "print(f\"Folder copied from {source_folder} to {destination_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../cyclegan/pytorch-CycleGAN-and-pix2pix/train.py --name test_svhn2mnist \\\n",
    "--dataroot ../x/jhoffman/cyclegan_data/svhn2mnist/ --resize_or_crop=None \\\n",
    "--loadSize=32 --fineSize=32 --which_model_netD n_layers --n_layers_D 3 \\\n",
    "--no_flip --model cycle_gan --lambda_A 1 --lambda_B 1 --lambda_identity 1.0 --gpu_ids 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#A Source-only model that is trained with the labelled source data and evaluated over the target data\n",
    "!python ../cyclegan/pytorch-CycleGAN-and-pix2pix/train.py --name ICDAR2013to2015_noIdentity \\\n",
    "--dataroot ../FY/cyclegan_data/ICDAR2013_2015/ --resize_or_crop=None \\\n",
    "--loadSize=32 --fineSize=32 --which_model_netD n_layers --n_layers_D 3 \\\n",
    "--no_flip --model cycle_gan --lambda_A 1 --lambda_B 1 --lambda_identity 0 --gpu_ids 0 --save_epoch_freq 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA_VISIBLE_DEVICES=1 \n",
    "!python cyclegan/pytorch-CycleGAN-and-pix2pix/train.py --name cycada_icdar132icdar15_noIdentity_semantic \\\n",
    "    --resize_or_crop=None \\\n",
    "    --loadSize=32 --fineSize=32 --which_model_netD n_layers --n_layers_D 3 \\\n",
    "    --model cycle_gan_semantic \\\n",
    "    --lambda_A 1 --lambda_B 1 --lambda_identity 0 \\\n",
    "    --no_flip --batchSize 100 \\\n",
    "    --dataset_mode icdar2013_icdar2015 --dataroot FY/ \\\n",
    "    --which_direction AtoB --gpu_ids -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x cyclegan/pytorch-CycleGAN-and-pix2pix/test_icdar2013to2015.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Path to the Bash script\n",
    "script_path = 'cyclegan/pytorch-CycleGAN-and-pix2pix/test_icdar2013to2015.sh'\n",
    "\n",
    "# Run the Bash script\n",
    "result = subprocess.run([script_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Print the output and error (if any)\n",
    "print(\"Output:\", result.stdout)\n",
    "print(\"Error:\", result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Source-only model that is trained with the labelled source data and evaluated over the target data;\n",
    "! python train_adda.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Source-only model that is trained with the labelled source data and evaluated over the target data;\n",
    "! python train_adda.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
