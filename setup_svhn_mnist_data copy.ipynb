{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cycada.data.data_loader import get_dataset\n",
    "import PIL.Image as Image\n",
    "from os.path import join\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "mnist_dataset = datasets.MNIST('../x/jhoffman/mnist/', train=True, transform=None, \n",
    "                               target_transform=None, download=True)\n",
    "svhn_dataset = datasets.SVHN('../x/jhoffman/svhn/', split='train', transform=None, \n",
    "                             target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Add other transformations if necessary, e.g., normalization\n",
    "    # transforms.Normalize((mean,), (std,))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64  # You can adjust the batch size as needed\n",
    "mnist_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over the DataLoader\n",
    "for i, (images, labels) in enumerate(mnist_loader):\n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Images Tensor Shape: {images.shape}\")\n",
    "    print(f\"Images Tensor Type: {images.dtype}\")\n",
    "    print(f\"Labels Tensor Shape: {labels.shape}\")\n",
    "    print(f\"Labels Tensor Type: {labels.dtype}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Optionally, break after the first batch if you just want to see the format of one batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=1 \n",
    "# !python train.py --name experiment_name \\ \n",
    "# --dataroot path_to_gta2cityscape --resize_or_crop=crop --loadSize=360 --fineSize=360 --identity 1.0 \\\n",
    "# --which_model_netD n_layers --n_layers_D 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "\n",
    "!python ../cyclegan/pytorch-CycleGAN-and-pix2pix/train.py --name test_svhn2mnist \\\n",
    "--dataroot ../x/jhoffman/cyclegan_data/svhn2mnist/ --resize_or_crop=None \\\n",
    "--loadSize=32 --fineSize=32 --which_model_netD n_layers --n_layers_D 3 \\\n",
    "--no_flip --model cycle_gan --lambda_A 1 --lambda_B 1 --lambda_identity 1.0 --gpu_ids 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/cycada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train_adda.py --name svhn2mnist-adaptive \\\n",
    "--dataroot FY/cyclegan_data/ICDAR2013_2015/ --resize_or_crop=None \\\n",
    "--loadSize=32 --fineSize=32 --which_model_netD n_layers --n_layers_D 3 \\\n",
    "--no_flip --model LeNet --lambda_A 1 --lambda_B 1 --lambda_identity 1.0 --gpu_ids -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering data params: svhn\n",
      "Registering data params: svhn\n",
      "Registering data params: usps\n",
      "Registering data params: usps\n",
      "Registering data params: mnist\n",
      "Registering data params: mnist\n",
      "Registering data params: svhn2mnist\n",
      "Registering data params: svhn2mnist\n",
      "Registering data params: usps2mnist\n",
      "Registering data params: usps2mnist\n",
      "Registering data params: mnist2usps\n",
      "Registering data params: mnist2usps\n",
      "Registering data params: cityscapes\n",
      "Registering data params: cityscapes\n",
      "Registering data params: gta5\n",
      "Registering data params: gta5\n",
      "Registering data params: cyclegta5\n",
      "Registering data params: icdar2013\n",
      "Registering data params: icdar2013\n",
      "Registering data params: icdar2015\n",
      "Registering data params: icdar2015\n",
      "-------Training net--------\n",
      "LeNet(\n",
      "  (conv_params): Sequential(\n",
      "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Dropout2d(p=0.5, inplace=False)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (fc_params): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "get dataset: icdar2015 FY/icdar2015 train\n",
      "get dataset: icdar2015 FY/icdar2015 test\n",
      "Training LeNet model for icdar2015\n",
      "[Train] Epoch: 0 [0/10869 (0%)]\tLoss: 0.695018  Acc: 53.91\n",
      "[Train] Epoch: 1 [0/10869 (0%)]\tLoss: 0.604274  Acc: 71.09\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_adda.py\", line 60, in <module>\n",
      "    lr=src_lr, betas=betas, weight_decay=weight_decay)\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/cycada/tools/train_task_net.py\", line 95, in train\n",
      "    train_epoch(train_data, net, opt_net, epoch)\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/cycada/tools/train_task_net.py\", line 25, in train_epoch\n",
      "    for batch_idx, (data, target) in enumerate(loader):\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/.venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/.venv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/.venv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/.venv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/cycada/data/icdar2015.py\", line 45, in __getitem__\n",
      "    image = Image.open(image_path)\n",
      "  File \"/Users/pomvrp/Documents/NTU AI Courses/AI6121 computer vision/18 Nov Project/cycada_release/.venv/lib/python3.7/site-packages/PIL/Image.py\", line 3236, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! python train_adda.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# A domain adaptive semantic segmentation model that is trained with the translated source data and evaluated over the target data.\n",
    "! python train_adda.py --name ICDAR2013to2015-adaptive \\\n",
    "--dataroot FY/cyclegan_data/ICDAR2013_2015/ --resize_or_crop=None \\\n",
    "--loadSize=32 --fineSize=32 --which_model_netD n_layers --n_layers_D 3 \\\n",
    "--no_flip --model LeNet --lambda_A 1 --lambda_B 1 --lambda_identity 1.0 --gpu_ids -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the path to your .sh file\n",
    "script_path = \"scripts/train_fcn_adda.sh\"\n",
    "\n",
    "# Run the shell script\n",
    "subprocess.run([\"bash\", script_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = join(outdir, 'trainB')\n",
    "for i in range(10):\n",
    "    img = Image.open(join(dirname, '{:d}.png'.format(i)))\n",
    "\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.grid('off')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = join(outdir, 'trainA')\n",
    "for i in range(10):\n",
    "    img = Image.open(join(dirname, '{:d}.png'.format(i)))\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.grid('off')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = svhn_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count,bins = np.histogram(y.squeeze(), bins=10)\n",
    "plt.bar(range(10), count); plt.title('P(Y) for SVHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_num = min(count)\n",
    "ind = np.zeros((10,min_num), dtype=int)\n",
    "for i in np.unique(y):\n",
    "    binary_ind = np.where(y.squeeze() == i)[0]\n",
    "    np.random.shuffle(binary_ind)\n",
    "    \n",
    "    ind[i-1,:] = binary_ind[:min_num]\n",
    "\n",
    "ind = ind.flatten()\n",
    "np.random.shuffle(ind)\n",
    "y_new = y[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_new,_ = np.histogram(y_new, bins=10)\n",
    "plt.bar(range(10), count_new); plt.title('P(Y) SVHN balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/x/jhoffman/cyclegan_data/svhn2mnist/trainA/labels.txt', 'r') as f:\n",
    "    data = f.read().splitlines()\n",
    "\n",
    "parse = np.array([(int(x.split(' ')[0]), int(x.split(' ')[1])) for x in data])\n",
    "d = dict(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Print original sys.path\n",
    "print(\"Original sys.path:\", sys.path)\n",
    "\n",
    "# Define the path you want to remove\n",
    "path_to_remove = '..'\n",
    "\n",
    "# Remove the path if it exists in sys.path\n",
    "sys.path = [p for p in sys.path if p != path_to_remove]\n",
    "\n",
    "# Print modified sys.path\n",
    "print(\"Modified sys.path:\", sys.path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
